{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab-10_2_mnist_deep_cnn.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"Collapsed":"false","id":"vTRVRurykycP"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"dXMdcEPmkztm"},"source":["cd drive/My Drive/수업/Info_Sys_2021/PyTorch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"Z-PJrLgkkWGf"},"source":["# Lab 11 MNIST and Deep learning CNN\n","import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"W3hgDn6jkWGl"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"-OOw4USikWGm"},"source":["# parameters\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"nSCKtycLkWGm"},"source":["# MNIST dataset\n","mnist_train = dsets.MNIST(root='MNIST_data/',\n","                          train=True,\n","                          transform=transforms.ToTensor(),\n","                          download=True)\n","\n","mnist_test = dsets.MNIST(root='MNIST_data/',\n","                         train=False,\n","                         transform=transforms.ToTensor(),\n","                         download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"ORp-xxqNkWGm"},"source":["# dataset loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n","                                          batch_size=batch_size,\n","                                          shuffle=True,\n","                                          drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"OsBVxoczkWGn"},"source":["# CNN Model\n","class CNN(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.keep_prob = 0.5\n","        # L1 ImgIn shape=(?, 28, 28, 1)\n","        #    Conv     -> (?, 28, 28, 32)\n","        #    Pool     -> (?, 14, 14, 32)\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        # L2 ImgIn shape=(?, 14, 14, 32)\n","        #    Conv      ->(?, 14, 14, 64)\n","        #    Pool      ->(?, 7, 7, 64)\n","        self.layer2 = torch.nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        # L3 ImgIn shape=(?, 7, 7, 64)\n","        #    Conv      ->(?, 7, 7, 128)\n","        #    Pool      ->(?, 4, 4, 128)\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        # L4 FC 4x4x128 inputs -> 625 outputs\n","        self.fc1 = nn.Linear(4 * 4 * 128, 625, bias=True)\n","        nn.init.xavier_uniform_(self.fc1.weight)\n","        self.layer4 = nn.Sequential(\n","            self.fc1,\n","            nn.ReLU(),\n","            nn.Dropout(p=1 - self.keep_prob))\n","        # L5 Final FC 625 inputs -> 10 outputs\n","        self.fc2 = nn.Linear(625, 10, bias=True)\n","        nn.init.xavier_uniform_(self.fc2.weight)\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0), -1)   # Flatten them for FC\n","        #print(out.shape)\n","        out = self.layer4(out)\n","        out = self.fc2(out)\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"z4YFaUBlkWGn"},"source":["# instantiate CNN model\n","model = CNN().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"-j0S6F0vkcQO"},"source":["### 비디오 lab-10-2 (30분 위치) model 확인하는 방법"]},{"cell_type":"code","metadata":{"id":"xGg7XZx0mo4f"},"source":["print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rCJSQDVuqdya"},"source":["모델에 training data를 넣어 돌리기 전에, 임의의 값을 넣어 테스트를 하는 것이 좋다."]},{"cell_type":"code","metadata":{"id":"QHTr2z6vmpBz"},"source":["value=torch.Tensor(1,1,28,28)\n","print(model(value).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q9XvnF48xPG3"},"source":["위 셀에서 value=torch.Tensor(1,1,28,28).to(device)로 변경해서 GPU에서 돌아갈수 있도록 한다.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bSWN8nZ2upVZ"},"source":["45번째 라인 # 제거한 다음, 그 셀부터 다시 실행한다. "]},{"cell_type":"markdown","metadata":{"id":"7SoVJ1FzvVEp"},"source":["1152 가 나오는데, 이를 128 (30번째 라인 참조)로 나누면 9가 나온다. \n","따라서, 30번째 라인 4\\*4\\*128 이 아니라 3\\*3\\*128 로 변경해야 한다.\n","즉 1152개의 출력셀을 3\\*3\\*128로 변환하여야 갯수가 일치한다."]},{"cell_type":"markdown","metadata":{"id":"o3KeYlUFwcBA"},"source":["45번째 라인을 코멘트 문으로 바꾸어야 한다.\n","그렇지 않으면 인쇄가 아주 많이 되어서 곤란해진다."]},{"cell_type":"code","metadata":{"id":"W0Km_CTFBtVY"},"source":["pip install pytorch_model_summary"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0d0sFxVB0GY"},"source":["import pytorch_model_summary\n","print(pytorch_model_summary.summary(model, torch.zeros(1, 1, 28, 28).to(device), show_input=False))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"couaZCPtkWGo"},"source":["# define cost/loss & optimizer\n","criterion = nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"1NzNxiBAkWGo"},"source":["# train my model\n","total_batch = len(data_loader)\n","model.train()    # set the model to train mode (dropout=True)\n","print('Learning started. It takes sometime.')\n","for epoch in range(training_epochs):\n","    avg_cost = 0\n","\n","    for X, Y in data_loader:\n","        # image is already size of (28x28), no reshape\n","        # label is not one-hot encoded\n","        X = X.to(device)\n","        Y = Y.to(device)\n","\n","        optimizer.zero_grad()\n","        hypothesis = model(X)\n","        cost = criterion(hypothesis, Y)\n","        cost.backward()\n","        optimizer.step()\n","\n","        avg_cost += cost / total_batch\n","\n","    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n","\n","print('Learning Finished!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"Collapsed":"false","id":"LRWNYXjckWGp"},"source":["# Test model and check accuracy\n","with torch.no_grad():\n","    model.eval()    # set the model to evaluation mode (dropout=False)\n","\n","    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","    Y_test = mnist_test.test_labels.to(device)\n","\n","    prediction = model(X_test)\n","    correct_prediction = torch.argmax(prediction, 1) == Y_test\n","    accuracy = correct_prediction.float().mean()\n","    print('Accuracy:', accuracy.item())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZqRARtZB865"},"source":["X.shape"],"execution_count":null,"outputs":[]}]}